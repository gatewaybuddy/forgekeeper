{
  "name": "L4-12K-0.7-4K",
  "description": "12K context, max_tokens=4096 (increased token limit)",
  "phase": "8-length",
  "requires_restart": false,
  "parameters": {
    "temperature": 0.7,
    "top_p": 0.8,
    "top_k": 0,
    "repetition_penalty": 1.0,
    "presence_penalty": 0.0,
    "frequency_penalty": 0.0,
    "length_penalty": 1.0,
    "max_tokens": 4096
  },
  "env_context": {
    "VLLM_MAX_MODEL_LEN": 12288
  }
}
