ARG VLLM_BASE_IMAGE=vllm/vllm-openai:latest
FROM ${VLLM_BASE_IMAGE}

# Persistent cache and logging directories (can be mounted via docker compose)
ENV HF_HOME=/root/.cache/huggingface \
    HUGGINGFACE_HUB_CACHE=/root/.cache/huggingface \
    VLLM_LOG_DIR=/var/log/vllm

RUN mkdir -p /root/.cache/huggingface /var/log/vllm

# Copy runtime scripts
WORKDIR /app
COPY scripts/run_vllm_core.sh scripts/run_vllm_coder.sh ./scripts/
RUN chmod +x ./scripts/run_vllm_core.sh ./scripts/run_vllm_coder.sh

# Default ports for Core and Coder
ENV VLLM_PORT_CORE=8000 \
    VLLM_PORT_CODER=8001
EXPOSE $VLLM_PORT_CORE $VLLM_PORT_CODER

ENTRYPOINT ["./scripts/run_vllm_core.sh"]
