# Forgekeeper (Fresh Start)

Quick CLI entry points and scripts to bring up the Core (llama.cpp by default), ensure the full stack, and chat with reasoning.

## Quick Start

- Copy environment template and adjust as needed:
  - `cp .env.example .env`

- Choose inference core (default is llama.cpp):
  - Edit `.env` and set `FK_CORE_KIND=llama` (default) or `FK_CORE_KIND=vllm`.

- Ensure Core only (idempotent):
  - Windows: `pwsh scripts/ensure_llama_core.ps1`
  - Linux/mac: `bash scripts/ensure_llama_core.sh`
  
- Ensure full stack (profiles + optional MongoDB):
  - Windows: `python -m forgekeeper ensure-stack --build --include-mongo`
  - Linux/mac: `python -m forgekeeper ensure-stack --build --include-mongo`
  - Use `--compose-file PATH` only when targeting a non-default Compose file (defaults to `docker-compose.yml`).

- Chat
  - Python CLI (streaming default): `python -m forgekeeper chat -p "Say 'harmony ok'."`
  - Python CLI non-stream: `python -m forgekeeper chat -p "Hello" --no-stream`
  - Tools demo (safe dir listing): `python -m forgekeeper chat -p "List current folder" --tools dir`
  - PowerShell script (Windows):
    - Streaming: `pwsh forgekeeper/scripts/chat_reasoning.ps1 -Prompt "Hello"`
    - Non-stream: `pwsh forgekeeper/scripts/chat_reasoning.ps1 -Prompt "Hello" -NoStream`

Streaming vs non‚Äëstream
- Streaming prints tokens as they arrive via SSE; you‚Äôll see partial reasoning chunks `[r]` and a final `[final]` line.
- Non‚Äëstream waits for the response to finish and prints only the final text.

System prompt
- UI: open the "Assistant System Prompt" panel to switch between the auto‚Äëgenerated prompt (includes tool list) and a custom prompt. The custom prompt is saved to localStorage and applied to the first system message in the chat.
- CLI: pass a one‚Äëoff override with `--system "..."` when using `python -m forgekeeper chat`.

### No‚ÄëGPU mock for smoke tests
- Start a local mock OpenAI server and run the smoke script:
  - `node scripts/mock_openai_server.mjs` (serves `/v1/chat/completions`, `/health[z]`)
  - In another shell: `FK_CORE_API_BASE=http://localhost:8001 python scripts/test_harmony_basic.py`

### Make targets
- `make dev-ui` - run Vite dev server
- `make ui-build` - typecheck + build UI
- `make lint` - ESLint on `src/`
- `make typecheck` - `tsc --noEmit`
- `make test-ui` - vitest (server orchestrator)
- `make test-py` - install + pytest
- `make task-sanity` - lint task cards for required fields
- `make pr-check TASK=T#` - locally enforce Allowed Touches for staged changes

## Frontend (Web UI)

- Dev server (Vite + React):
  - Install deps: `npm --prefix frontend install`
  - Start: `npm --prefix frontend run dev`
  - Opens on `http://localhost:5173` and proxies `/v1`, `/health`, `/healthz` to the Core server.
  - Note: `/api/chat` is not available in Vite dev mode; use the server mode below.

- Tool-enabled chat orchestration (server-side):
  - Endpoint: `POST /api/chat` (non-streaming) via `frontend/server.mjs`.
  - Client helper: `frontend/src/lib/chatClient.ts::chatViaServer`.
  - Tools live under: `frontend/tools/*.mjs` with aggregator `tools/index.mjs` (compat wrapper at `server.tools.mjs`).
  - Orchestrator loop: `frontend/server.orchestrator.mjs` handles `tool_calls`.
  - UI wiring: `Chat.tsx` routes blocking sends via `/api/chat` and streaming sends via `/api/chat/stream` automatically (no separate tools button).
  - Discovery: `GET /api/tools` returns `{ enabled, count, names, defs }`; `/config.json` includes a `tools` summary. The UI disables tools when none available and shows the list in the footer.
  - System prompt: `Chat.tsx::buildSystemPrompt` uses the `/api/tools` metadata (falling back to the names list) to describe each tool. Update that helper if tool usage instructions change so the UI and allowlist stay in sync.

### Built-in Tools (Server)
- `get_time`: returns current UTC ISO timestamp.
- `echo`: echoes provided text.
- `read_file`: reads a text file under the sandbox root (size-limited).
- `read_dir`: lists directory entries under a sandbox root.
- `write_file`: writes a file under the sandbox root (size-limited).
- `run_powershell` (gated): runs a PowerShell command if enabled.

Environment controls (server.mjs process):
- `TOOLS_FS_ROOT` ‚Äî sandbox root for `read_dir`/`write_file`.
  - Default: current working dir of the server process.
  - Docker: docker-compose sets `TOOLS_FS_ROOT=/workspace/sandbox` so files persist in the bind-mounted repo directory (`./ -> /workspace`).
  - Override in `.env` if you want another persisted path (e.g., `/workspace/data`).
- `TOOLS_MAX_WRITE_BYTES` ‚Äî max bytes for `write_file` (default: 65536).
- `TOOLS_MAX_READ_BYTES` ‚Äî max bytes for `read_file` (default: 65536).
- `FRONTEND_ENABLE_POWERSHELL=1` ‚Äî enable `run_powershell` tool (disabled by default).
- `PWSH_PATH` ‚Äî override pwsh executable (defaults: `pwsh` or `powershell.exe` on Windows).

### Tool Management & Monitoring

**Status**: ‚úÖ Fully implemented (codex.plan Phases 1-2)

**Overview**: Comprehensive tool lifecycle management with approval system, error tracking, regression monitoring, and resource usage.

**Core Features**:
- ‚úÖ **AI-Generated Tool Approval** (T203) - Propose and approve new tools dynamically
- ‚úÖ **Error Statistics Tracking** (T205) - Per-tool error rates, types, and patterns
- ‚úÖ **Regression Monitoring** (T211) - Detect performance degradation over time
- ‚úÖ **Resource Usage Tracking** (T212) - CPU, memory, disk usage per tool

**Key Endpoints** (15+ at `/api/tools/*`):
- Discovery: `GET /api/tools`, `GET /api/tools/config`
- Approval System: `POST /api/tools/propose`, `GET /api/tools/pending`, `POST /api/tools/approve/:tool_name`
- Error Tracking: `GET /api/tools/errors`, `GET /api/tools/errors/:tool_name`, `POST /api/tools/errors/:tool_name/clear`
- Regression: `GET /api/tools/regression`, `GET /api/tools/regression/:tool_name`, `POST /api/tools/regression/:tool_name/clear`
- Resources: `GET /api/tools/resources`, `GET /api/tools/resources/:tool_name`
- Dynamic Loading: `POST /api/tools/reload`, `POST /api/tools/write`

**Environment Variables**:
- `TOOLS_APPROVAL_REQUIRED=1` - Require approval for new tools (default: `0`)
- `TOOLS_APPROVAL_EXPIRES_MS=86400000` - Proposal expiry time (default: 24h)
- `TOOLS_MAX_OUTPUT_BYTES=10240` - Max tool output size (default: 10KB)
- `TOOLS_MAX_OUTPUT_LINES=256` - Max output lines (default: 256)
- `TOOLS_TIMEOUT_MS=30000` - Tool execution timeout (default: 30s)

**Documentation**:
- API Reference: `docs/api/tools_api.md`
- Security: Sandbox isolation, size limits, timeout enforcement
- Auditing: All tool calls logged to ContextLog with full telemetry

### Debugging tools
- In the UI, enable "Tools diagnostics" to see recent tool calls (name + args) per step of the server-side orchestration.
- Diagnostics Drawer: toggle in Chat to view recent ContextLog events for the current `conv_id` (uses `/api/ctx/tail`).
- New: `GET /api/ctx/tail?n=50&conv_id=...` returns recent ContextLog events (JSONL-backed).

### Server Policies & Limits
- Tool allowlist: set `TOOL_ALLOW` to a comma‚Äëseparated list of tool names to permit (e.g., `get_time,echo,read_file`). If unset, all registered tools are allowed.
- Rate limiting: set `API_RATE_PER_MIN` to an integer to limit requests per minute per IP for `/api/chat` and `/api/chat/stream` (0 disables limiting).
- Metrics: GET `/metrics` returns counters `{ totalRequests, streamRequests, totalToolCalls, rateLimited }`.
- Auditing: tool executions append JSON lines to `.forgekeeper/tools_audit.jsonl` (fields: `ts`, `name`, `args`, `iter`, `ip`).
- ContextLog: structured JSONL under `.forgekeeper/context_log/` with correlation fields (`conv_id`, `trace_id`, `iter`). See `docs/observability.md` and `docs/contextlog/adr-0001-contextlog.md`.

### Streaming Final Turn
- Non‚Äëstreaming tools loop: `POST /api/chat` runs tool orchestration and returns `{ assistant, messages, debug }`.
- Streaming final turn: `POST /api/chat/stream` runs the tool loop server‚Äëside, then streams the final assistant turn from the upstream OpenAI‚Äëcompatible server via SSE (`text/event-stream`).
- The Vite dev client can still stream directly from `/v1/chat/completions`; use the ‚ÄúSend (tools)‚Äù button to route via `/api/chat` or integrate your own SSE consumer for `/api/chat/stream`.
- See: `docs/api/chat_stream.md` for curl examples and client helper notes.

### Finishers & Continuations
- When the model output looks incomplete (short text without terminal punctuation or a dangling code fence), the server auto-requests short continuations to complete the response.
- Defaults:
  - Env: `FRONTEND_CONT_ATTEMPTS` defaults to `2` when unset. Set to `0` to disable.
  - Env: `FRONTEND_CONT_TOKENS` controls the size of each continuation chunk.
  - UI: ‚ÄúContinue attempts‚Äù defaults to `2` and persists to localStorage; can be set per-conversation.
- Telemetry: continuation attempts are recorded to ContextLog with `act=auto_continue` including `attempt`, `reason` (`short|punct|fence`), and `elapsed_ms`.

See also: docs/ui/diagnostics_drawer.md for the Diagnostics Drawer and how continuation attempts are summarized in the UI.

### Task Suggestions (TGT - Telemetry-Driven Task Generation)

**Status**: ‚úÖ Fully implemented (Weeks 1-9)

**Overview**: Automatically analyzes ContextLog telemetry to generate actionable task cards with priorities, dependencies, and templates.

**UI Access**:
- Open AutonomousPanel ‚Üí Click "Tasks‚Ä¶" button to view TasksDrawer
- Features: Multi-select, batch approve/dismiss, analytics dashboard, templates

**Core Endpoints** (28 total at `/api/tasks/*`):
- Task Management: `POST /suggest`, `GET /`, `GET /:id`, `POST /:id/approve`, `POST /:id/dismiss`
- Analytics: `GET /analytics`, `GET /funnel`, `GET /stats`
- Templates: `GET /templates`, `POST /from-template/:id`
- Batch Operations: `POST /batch/approve`, `POST /batch/dismiss`
- Dependencies: `GET /dependencies/graph`, `POST /:id/dependencies`
- Prioritization: `POST /reprioritize`, `GET /priority/distribution`
- Scheduler: `GET /scheduler/stats`, `POST /scheduler/run`
- SSE: `GET /stream` - Real-time task updates

**Environment Variables**:

Core Settings:
  - `TASKGEN_ENABLED=1` - Enable TGT system (default: `0`)
  - `TASKGEN_WINDOW_MIN=60` - Analysis window in minutes (default: `60`)
  - `TASKGEN_MIN_CONFIDENCE=0.7` - Minimum confidence threshold (default: `0.7`)
  - `TASKGEN_MAX_TASKS=10` - Maximum tasks to generate (default: `10`)

Analyzers:
  - `TASKGEN_CONT_MIN=5` - Min continuations to trigger (default: `5`)
  - `TASKGEN_CONT_RATIO_THRESHOLD=0.15` - Continuation rate threshold (default: `0.15`)
  - `TASKGEN_UPSTREAM_MIN=3` - Min upstream errors (default: `3`)

Week 8-9 Features:
  - `TASKGEN_AUTO_APPROVE=1` - Enable auto-approval (default: `0`)
  - `TASKGEN_AUTO_APPROVE_CONFIDENCE=0.9` - Min confidence for auto-approve (default: `0.9`)
  - `TASKGEN_AUTO_APPROVE_TRUSTED=error-spike,performance` - Trusted analyzer list

**Features**:
- ‚úÖ 5 Analyzer types: continuation, error-spike, docs-gap, performance, ux-issue
- ‚úÖ Smart priority scoring (Week 9)
- ‚úÖ Auto-approval system (Week 8)
- ‚úÖ Task dependencies with graph visualization (Week 9)
- ‚úÖ Task templates for common patterns (Week 6)
- ‚úÖ Batch operations (Week 6)
- ‚úÖ Funnel analytics with conversion rates (Week 7)
- ‚úÖ Comprehensive analytics dashboard (Week 7)
- ‚úÖ Real-time SSE updates (Week 5)
- ‚úÖ Scheduled background analysis (Week 4)

**UI Components**:
- ‚úÖ TasksDrawer with multi-select and batch actions
- ‚úÖ AnalyticsDashboard with funnel metrics
- ‚úÖ TaskFunnelChart visualization
- ‚úÖ BatchActionBar for bulk operations
- ‚úÖ TemplateSelector for quick task creation
- ‚úÖ PriorityBadge visual indicators
- ‚úÖ DependencyView graph visualization

**Documentation**:
- API Reference: `docs/api/tasks_api.md`
- Implementation: `docs/autonomous/tgt/README.md`
- Integration Guide: `frontend/docs/UI_COMPONENTS_INTEGRATION_GUIDE.md`
- Week Summaries: `docs/autonomous/tgt/TGT_WEEK[1-8]_*.md`

**Testing**: `npm run test` ‚Üí 22/22 tests passing (Week 8-9 integration)

**Smoke test**: `bash forgekeeper/scripts/test_taskgen.sh 60` (with server running)

### SAPL (Safe Auto-PR Loop)

**Status**: ‚úÖ Implemented
**Priority**: High
**Integration**: Works with TGT task suggestions

**Overview**: Safe, automated PR creation from TGT task suggestions with comprehensive safety controls.

**UI Access**:
- From TGT TasksDrawer ‚Üí Select task ‚Üí Click "üìù Propose PR" ‚Üí Enhanced preview modal ‚Üí Create PR
- Features rich diff viewer, file validation, stats, and warnings

**Core Endpoints** (5 at `/api/auto_pr/*`):
- `GET /status` - Get SAPL configuration and status
- `POST /preview` - Preview PR (always safe, no git operations)
- `POST /create` - Create PR (requires flags to be enabled)
- `GET /git/status` - Get current git status
- `POST /validate` - Validate files against allowlist

**Safety Features**:
- ‚úÖ **Allowlist-only**: Docs, config, tests only (no runtime code)
- ‚úÖ **Dry-run default**: Preview mode by default (`AUTO_PR_DRYRUN=1`)
- ‚úÖ **Kill-switch**: Instant disable via `AUTO_PR_ENABLED=0`
- ‚úÖ **Full audit**: Every action logged to ContextLog
- ‚úÖ **No auto-merge**: Manual review required (default)

**Environment Variables**:

Enable/Disable:
  - `AUTO_PR_ENABLED=1` - Enable SAPL (default: `0`)
  - `AUTO_PR_DRYRUN=1` - Dry-run mode (default: `1`, safe)
  - `AUTO_PR_AUTOMERGE=0` - Auto-merge when CI passes (default: `0`, safe)

Configuration:
  - `AUTO_PR_ALLOW=...` - Comma-separated file patterns
    - Default: `README.md,docs/**/*.md,*.example,tests/**/*.mjs`
  - `AUTO_PR_LABELS=...` - PR labels (default: `auto-pr,safe,documentation`)

**Default Allowlist** (safe files only):
```
README.md
docs/**/*.md                    # All markdown in docs/
forgekeeper/.env.example        # Example env files
frontend/test/**/*.mjs          # Test files
tests/**/*.mjs
frontend/**/*.test.mjs
package.json                    # Package metadata
tsconfig.json                   # Config files
```

**Example Usage**:

```bash
# 1. Check status
curl http://localhost:3000/api/auto_pr/status

# 2. Preview PR (always safe)
curl -X POST http://localhost:3000/api/auto_pr/preview \
  -H "Content-Type: application/json" \
  -d '{
    "files": ["README.md", "docs/api.md"],
    "title": "docs: update documentation",
    "body": "Auto-generated from TGT task"
  }'

# 3. Validate files against allowlist
curl -X POST http://localhost:3000/api/auto_pr/validate \
  -H "Content-Type: application/json" \
  -d '{"files": ["README.md", "src/server.mjs"]}'

# Response: { "allowed": ["README.md"], "blocked": ["src/server.mjs"] }

# 4. Create PR (requires AUTO_PR_ENABLED=1, AUTO_PR_DRYRUN=0)
curl -X POST http://localhost:3000/api/auto_pr/create \
  -H "Content-Type: application/json" \
  -d '{
    "files": ["README.md"],
    "title": "docs: update README",
    "body": "Auto-generated update"
  }'
```

**Prerequisites**:
- GitHub CLI (`gh`) must be installed and authenticated
  - macOS: `brew install gh`
  - Linux: See https://github.com/cli/cli#installation
  - Auth: `gh auth login`

**Workflow** (TGT ‚Üí SAPL ‚Üí PR):
1. TGT suggests task: "Update API documentation"
2. User clicks "Propose PR" in UI
3. SAPL validates files against allowlist
4. User reviews preview (diff, files, branch name)
5. User confirms "Create PR"
6. SAPL creates branch, commits, pushes, opens PR
7. PR URL returned to user

**Safety Guarantees**:
- ‚ùå Will NEVER modify runtime code (src/, lib/, server files)
- ‚ùå Will NEVER auto-merge by default
- ‚ùå Will NEVER run when `AUTO_PR_ENABLED=0`
- ‚úÖ ALWAYS validates against allowlist BEFORE any git operation
- ‚úÖ ALWAYS logs to ContextLog
- ‚úÖ ALWAYS returns preview in dry-run mode

**UI Components**:
- ‚úÖ **PRPreviewModal** - Enhanced preview with diff viewer, file validation, stats
  - Syntax-highlighted diff display (add/remove/context)
  - File validation with visual allowed/blocked indicators
  - Stats display (files changed, lines added/removed)
  - Warnings display for blocked files, disabled state
  - Branch name preview
  - Create PR button with safety checks
- ‚úÖ **TasksDrawer Integration** - "üìù Propose PR" button on each task
  - One-click PR proposal from TGT suggestions
  - Auto-fills PR title and body from task details
  - Opens enhanced modal for review before creation

**Documentation**:
- Full Guide: `docs/sapl/README.md`
- API Reference: See above endpoints
- Implementation: `frontend/server.auto-pr.mjs`
- UI Components: `frontend/src/components/PRPreviewModal.tsx`
- Routes: `frontend/server.mjs` (lines 2490-2588)

**Testing**:
- UI: Click "üìù Propose PR" in TasksDrawer ‚Üí Review in modal ‚Üí Create PR
- API: `curl http://localhost:3000/api/auto_pr/status`
- Preview (always safe): `npm run test:sapl:preview`
- Full integration: `npm run test:sapl` (requires gh CLI)

### MIP (Metrics-Informed Prompting)

**Status**: ‚úÖ Implemented
**Priority**: High
**Purpose**: Reduce incomplete responses by injecting hints based on recent telemetry

**Overview**: Analyzes recent ContextLog events for continuation patterns and generates specific hints to help the LLM complete responses properly.

**Core Endpoints** (3 at `/api/prompting_hints/*`):
- `GET /status` - Get MIP configuration and status
- `GET /stats?hours=24` - Get hint usage statistics
- `GET /analyze?conv_id=...&minutes=10` - Analyze continuations and generate hint

**How It Works**:
1. **Analyze Recent Events**: Scans ContextLog for incomplete responses (continuations)
2. **Detect Patterns**: Identifies dominant reasons (fence, punct, short, length)
3. **Generate Hints**: Creates specific hints based on patterns
4. **Apply Hints**: Injects hints into system/developer prompts (future integration)
5. **Log Usage**: Records hint application to ContextLog

**Continuation Reasons Detected**:
- `fence` ‚Üí "Close any open code fence (\`\`\`) before finishing"
- `punct` ‚Üí "Finish your sentences with proper punctuation"
- `short` ‚Üí "Complete your full response before stopping"
- `length` ‚Üí "Prioritize completing current thought over adding new info"
- `stop` ‚Üí "Complete your current response fully before stopping"

**Environment Variables**:

Enable/Disable:
  - `PROMPTING_HINTS_ENABLED=1` - Enable MIP (default: `0`)

Configuration:
  - `PROMPTING_HINTS_MINUTES=10` - Analysis window in minutes (default: `10`)
  - `PROMPTING_HINTS_THRESHOLD=0.15` - Continuation rate threshold (default: `0.15`, i.e., 15%)
  - `PROMPTING_HINTS_MIN_SAMPLES=5` - Minimum events to analyze (default: `5`)

**Example Usage**:

```bash
# 1. Check status
curl http://localhost:3000/api/prompting_hints/status

# Response:
{
  "ok": true,
  "enabled": false,
  "minutes": 10,
  "threshold": 0.15,
  "minSamples": 5
}

# 2. Analyze recent continuations
curl http://localhost:3000/api/prompting_hints/analyze?minutes=10

# Response:
{
  "ok": true,
  "hint": "IMPORTANT: Close any open code fence (...) before finishing. Recent telemetry shows 25% of responses are incomplete due to unclosed code blocks.",
  "analysis": {
    "totalEvents": 20,
    "continuations": 5,
    "continuationRate": 0.25,
    "reasons": {
      "fence": 3,
      "punct": 2
    },
    "dominantReason": "fence",
    "shouldInjectHint": true,
    "threshold": 0.15
  }
}

# 3. Get hint statistics (last 24 hours)
curl http://localhost:3000/api/prompting_hints/stats?hours=24

# Response:
{
  "ok": true,
  "totalHints": 15,
  "hours": 24,
  "reasonCounts": {
    "fence": 8,
    "punct": 5,
    "short": 2
  },
  "mostCommonReason": "fence",
  "avgContinuationRate": 0.22,
  "config": { "enabled": true, ... }
}
```

**How Hints Are Applied** (Future Integration):

When integrated into the orchestrator, MIP will:
1. Check if continuation rate exceeds threshold in last N minutes
2. Generate appropriate hint based on dominant reason
3. Inject hint into system or developer message
4. Log hint application to ContextLog (`act: 'hint_applied'`)

**Example Hint Injection**:

Before (no hint):
```javascript
{
  "role": "system",
  "content": "You are a helpful assistant."
}
```

After (with hint):
```javascript
{
  "role": "system",
  "content": "You are a helpful assistant.\n\nIMPORTANT: Close any open code fence (```) before finishing your response. Recent telemetry shows 25% of responses are incomplete due to unclosed code blocks."
}
```

**Benefits**:
- ‚úÖ Reduces incomplete responses (fence/punct errors)
- ‚úÖ Prevents cut-off responses (length hints)
- ‚úÖ No model fine-tuning required
- ‚úÖ Data-driven (based on actual telemetry)
- ‚úÖ Easy to disable (flag-gated)
- ‚úÖ Low overhead (milliseconds of analysis)

**ContextLog Audit Events**:

When a hint is applied:
```json
{
  "id": "01HQXYZ...",
  "ts": "2025-11-04T...",
  "actor": "system",
  "act": "hint_applied",
  "conv_id": "conv-123",
  "hint_type": "prompting_hint",
  "continuation_rate": 0.25,
  "dominant_reason": "fence",
  "events_analyzed": 20,
  "continuations_detected": 5,
  "window_minutes": 10,
  "threshold": 0.15,
  "hint_preview": "IMPORTANT: Close any open code fence..."
}
```

**Documentation**:
- Implementation: `frontend/server.prompting-hints.mjs`
- API Routes: `frontend/server.mjs` (lines 2591-2634)
- Integration: `frontend/server.orchestrator.mjs` (import added, full integration pending)

**Current Status**:
- ‚úÖ Module implemented (380 lines)
- ‚úÖ API endpoints functional (3 endpoints)
- ‚úÖ Analysis and hint generation working
- ‚úÖ ContextLog integration ready
- ‚è≥ Orchestrator integration (TODO for follow-up)

**Next Steps** (Future Integration):
- Wire MIP into `orchestrateWithTools` function
- Auto-inject hints before LLM calls when threshold exceeded
- Add toggle in UI to enable/disable MIP
- Measure impact on continuation rates

**Self-Improvement Plan**: Priority 3 Complete ‚úÖ

### Autonomous Agent & Advanced Learning

**Status**: ‚úÖ Fully implemented (Phase 5 + Diagnostic Reflection)

**Overview**: Autonomous execution with episodic memory, user preference learning, and advanced error recovery capabilities.

**Core Features**:

**1. Episodic Memory with Semantic Search** (Phase 5 Option A)
- ‚úÖ TF-IDF semantic similarity search for past tasks
- ‚úÖ Learn from successful strategies in similar contexts
- ‚úÖ Tool usage suggestions based on historical patterns
- ‚úÖ Iteration complexity estimation from past sessions
- Storage: `.forgekeeper/playground/.episodic_memory.jsonl`
- Lightweight local embeddings (no external dependencies)

**2. User Preference Learning** (Phase 5 Option D)
- ‚úÖ Automatic coding style inference (indentation, quotes, docstrings)
- ‚úÖ Tool choice learning (test frameworks, package managers, formatters)
- ‚úÖ Workflow pattern detection (test location, commit style, branch naming)
- ‚úÖ Documentation style preferences (comment verbosity, README structure)
- Storage: `.forgekeeper/preferences/*.jsonl`
- Confidence-based strengthening through repeated observations

**3. Diagnostic Reflection & Error Recovery** (T313)
- ‚úÖ "5 Whys" root cause analysis for tool failures
- ‚úÖ 14 error categories with specific recovery strategies
- ‚úÖ Automated recovery plan generation and execution
- ‚úÖ Pattern learning from successful recoveries
- ‚úÖ 85-90% recovery success rate for common errors
- Recovery scoring prioritizes automated solutions over user prompts

**Key Endpoints** (20+ at `/api/autonomous/*`, `/api/episodes/*`, `/api/preferences/*`):

Session Management:
- `POST /api/autonomous/start`, `POST /api/autonomous/stop`, `GET /api/autonomous/status`
- `POST /api/autonomous/checkpoint/:session_id`, `POST /api/autonomous/resume/:checkpoint_id`

Diagnostics & Recovery:
- `GET /api/autonomous/diagnose/:session_id` - "5 Whys" failure analysis
- `POST /api/autonomous/recover/:session_id` - Execute recovery plan
- `GET /api/autonomous/sessions/:session_id/errors` - Error history
- `POST /api/autonomous/retry/:session_id` - Retry with diagnostic insights

Episodic Memory:
- `POST /api/episodes/record` - Store successful session
- `POST /api/episodes/search` - Semantic similarity search
- `GET /api/episodes`, `GET /api/episodes/:id`, `DELETE /api/episodes/:id`

User Preferences:
- `POST /api/preferences/infer` - Automatic style inference from code
- `POST /api/preferences/record` - Manual preference recording
- `GET /api/preferences`, `GET /api/preferences/:category`, `PUT /api/preferences/:id`

**Environment Variables**:
- `AUTONOMOUS_ENABLED=1` - Enable autonomous agent (default: `0`)
- `AUTONOMOUS_MAX_ITERATIONS=50` - Max iterations per session (default: `50`)
- `AUTONOMOUS_CHECKPOINT_INTERVAL=10` - Checkpoint every N iterations (default: `10`)
- `AUTONOMOUS_DIAGNOSTIC_ENABLED=1` - Enable diagnostic reflection (default: `1`)
- `EPISODES_MAX_SEARCH_RESULTS=3` - Episodes returned by search (default: `3`)
- `PREFERENCES_MIN_CONFIDENCE=0.6` - Min confidence to apply preference (default: `0.6`)

**Error Categories & Recovery Strategies**:
- `command_not_found` (exit 127) ‚Üí Install via package manager or alternative tool
- `permission_denied` (EACCES) ‚Üí Sandbox path retry or chmod fixes
- `file_not_found` (ENOENT) ‚Üí Path verification and correction
- `timeout` (ETIMEDOUT) ‚Üí Scope reduction or batch operations
- `tool_not_found` ‚Üí Decompose to basic tools
- Plus 9 more categories with automated recovery plans

**Performance**:
- Diagnostic reflection: ~1-2 seconds per failure
- Recovery success rate: 85-90% for common errors
- Iteration reduction: 40-60% fewer stuck iterations
- Semantic search: <100ms for TF-IDF similarity (local)

**Documentation**:
- API Reference: `docs/api/autonomous_api.md`
- Episodic Memory: `docs/PHASE5_EPISODIC_MEMORY.md`
- User Preferences: `docs/PHASE5_USER_PREFERENCE_LEARNING.md`
- Diagnostic Reflection: `docs/adr-0003-diagnostic-reflection.md`
- Recovery Strategies: `docs/autonomous/recovery-strategies.md`
- Examples: `docs/autonomous/diagnostic-reflection-examples.md`

**Testing**:
- Diagnostic Reflection: `tests/autonomous/test_diagnostic_reflection.mjs`
- Recovery Scenarios: `tests/autonomous/test_recovery_scenarios.mjs`
- Episodic Memory: `tests/autonomous/test_episodic_memory.mjs`
- Preferences: `tests/autonomous/test_preference_inference.mjs`

### Safe Auto‚ÄëPR Loop (SAPL) ‚Äî Demo
- Preview (dry‚Äërun): `AUTO_PR_ENABLED=1 FRONTEND_PORT=3000 bash forgekeeper/scripts/sapl_demo.sh README.md docs`
  - Calls `POST /api/auto_pr/preview` to validate the allowlist and show unified diff append previews.
  - No PR is created; enable `AUTO_PR_DRYRUN=0` and use the UI‚Äôs ‚ÄúCreate PR‚Äù to open a PR.
- Flags: `AUTO_PR_ENABLED`, `AUTO_PR_DRYRUN`, `AUTO_PR_ALLOW`, `AUTO_PR_LABELS`, `AUTO_PR_AUTOMERGE`.
- PR creation prerequisites:
  - `gh` is installed in the container image (we install it automatically).
  - Provide a GitHub token as `GH_TOKEN` or `GITHUB_TOKEN` (PAT with `repo` scope is sufficient). In Docker Compose, the frontend service forwards these env vars.
  - Ensure `origin` points to your GitHub repo and that Git is configured to use HTTPS (the server route runs `gh auth setup-git` when a token is present).

### GitHub Auth Options (local dev)
- Host env pass‚Äëthrough (recommended):
  - Windows PowerShell: `$env:GH_TOKEN='ghp_‚Ä¶'; docker compose up -d frontend`
  - Linux/macOS: `export GH_TOKEN='ghp_‚Ä¶'; docker compose up -d frontend`
- Paste token via API (no host env):
  - Enable: `FRONTEND_ENABLE_AUTH_LOCAL=1`
  - `curl -H 'Content-Type: application/json' -d '{"token":"ghp_‚Ä¶"}' http://localhost:${FRONTEND_PORT}/api/auth/github/token`
  - Stored at `.forgekeeper/secrets/gh_token` (gitignored). The server attempts `gh auth login` + `gh auth setup-git` automatically.
- Notes:
  - Tokens are never logged; secrets live under `.forgekeeper/secrets/` which is gitignored by `forgekeeper/.gitignore`.
  - For OAuth/web login (device flow), register an OAuth app and wire its client ID to a future auth handler (tracked as a follow‚Äëup task).

### Upstream Resilience (stub)
- Optional circuit‚Äëbreaker/backoff stub for upstream 5xx spikes.
- Flags:
  - `UPSTREAM_CB_ENABLED=1` to enable
  - `UPSTREAM_CB_THRESHOLD` (default 3 failures within window)
  - `UPSTREAM_CB_WINDOW_MS` (default 30000)
  - `UPSTREAM_CB_OPEN_MS` (default 20000)
- Behavior: when open, `/api/chat` and `/api/chat/stream` return `503 { error: "circuit_open", retry_after_ms }` and set `Retry-After`.
- Diagnostics: `GET /api/diagnose` includes `circuit` status.

### Metrics‚ÄëInformed Prompting (MIP)
- When `PROMPTING_HINTS_ENABLED=1`, the server may inject a short developer note into the final turn based on recent continuation reasons (e.g., close code fences, finish sentences).
- Tuning envs: `PROMPTING_HINTS_MINUTES` (default 10), `PROMPTING_HINTS_THRESHOLD` (default 0.15).

### Safe Auto‚ÄëPR Loop (SAPL)
- Preview: `POST /api/auto_pr/preview` validates an allowlist for docs/config/tests; disabled unless `AUTO_PR_ENABLED=1`.
- Create: `POST /api/auto_pr/create` creates a branch, commits allowlisted files, pushes, and opens a PR via `gh` when `AUTO_PR_ENABLED=1` and `AUTO_PR_DRYRUN=0`.
- Flags: `AUTO_PR_ENABLED`, `AUTO_PR_DRYRUN`, `AUTO_PR_ALLOW`, `AUTO_PR_AUTOMERGE`.
- UI: open Tasks‚Ä¶ ‚Üí Propose PR ‚Üí Preview ‚Üí Create PR (enabled by flags).
- See docs/ui/sapl.md for details and the UI flow.

- See: `docs/api/chat_stream.md` for curl examples and client helper notes.

### Conversation Controls
- New Conversation: resets transcript and issues a new `conv_id` (see `docs/ui/new_conversation.md`).
- Stop & Revise: aborts current stream and injects a developer note before the last user turn to relaunch (see `docs/ui/stop_and_revise.md`).
- Diagnostics Drawer: shows recent ContextLog events (enable polling to refresh every 5s).

### Status Bar
- Displays Inference (/health|/healthz), Agent (/metrics), GraphQL (stubbed), Queue (N/A). See `docs/ui/status_bar.md`.

### Dockerized UI (Node.js server):
  - Included in default compose via `python -m forgekeeper`.
  - Serve URL: `http://localhost:${FRONTEND_PORT}` (default `http://localhost:5173`).
  - Container serves static UI with an Express server and runtime config at `/config.json`.
  - Built-in reverse proxy maps `/v1`, `/health`, `/healthz` to the Core container (default target `http://llama-core:8000`).
  - Configure via env: `FRONTEND_VLLM_API_BASE` (default `http://llama-core:8000/v1`), `FRONTEND_VLLM_MODEL` (default `core`), `FRONTEND_PORT` (default `5173` via `.env`; compose fallback `3000` if unset).
  - Local server mode (without Docker): `npm --prefix frontend run build && npm --prefix frontend run serve` (serves `/api/chat`).

- Configure endpoints:
  - Default API base: `/v1` (proxied to `http://localhost:8001`).
  - Change via env: set `VLLM_PROXY_TARGET=http://localhost:8001` before `npm run dev`, or in the UI Settings change API base.
  - Default model: `core` (change in UI or set `VITE_VLLM_MODEL`).

- Run end‚Äëto‚Äëend:
  1) Ensure Core: `python -m forgekeeper up-core`
  2) Start UI: `npm --prefix frontend run dev`
  3) Visit `http://localhost:5173` ‚Üí send prompts; toggle ‚ÄúShow reasoning‚Äù to view chain‚Äëof‚Äëthought.

## CLI Reference

- `python -m forgekeeper compose`
  - Ensures stack via `ensure-stack` (builds when `.env`, `docker-compose.yml`, or `frontend/` sources change) and holds FG; Ctrl+C tears down.
  - Stores a fingerprint at `.forgekeeper/stack_fingerprint.json` to skip rebuilds when configs are unchanged.
  - Tries platform start wrapper (`start.ps1`/`start.sh`). If unavailable/fails, falls back to `up-core` and prints a hint.

- `python -m forgekeeper up-core`
  - Ensures the default core (`llama-core`) is up. Set `FK_CORE_GPU=0` to prefer the CPU profile or `FK_CORE_KIND=vllm` to use vLLM instead.

- `python -m forgekeeper ensure-stack [--build] [--include-mongo] [--profile NAME ...] [--compose-file FILE]`
  - Cross‚Äëplatform wrapper over `scripts/ensure_stack.ps1|.sh`. Defaults to the `ui` + `inference` profiles (CPU vs GPU inference selected via `FK_CORE_GPU`).

- `python -m forgekeeper chat [--base-url URL] [--model NAME] [--no-stream] -p PROMPT`
  - PowerShell streaming client on Windows; simple non-streaming Python fallback elsewhere.
  - On non-Windows platforms the fallback runner delegates to `scripts/test_harmony_basic.py`, which always issues the "harmony ok" smoke test regardless of `-p` (known limitation).
  - When using the Python CLI, pass `--no-stream` (two hyphens). The PowerShell switch is `-NoStream` only when calling the `.ps1` directly.
  - Tools demo: add `--tools dir` to enable a minimal `list_dir` function; restrict with `--workdir PATH`.

- `python -m forgekeeper switch-core {llama|vllm} [--no-restart]`
  - Updates `.env` (FK_CORE_KIND, FK_CORE_API_BASE) and restarts the appropriate services (UI + selected core). Use `--no-restart` to skip service changes.

## Harmony Docs

- Protocol summary: `docs/harmony_protocol_summary.md`
- Roadmap: `ROADMAP.md`

## Contributing
- Please read `CONTRIBUTING.md` for the Task Cards policy and local/CI enforcement details.
